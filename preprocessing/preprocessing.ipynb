{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#from scipy import stats\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "Click <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "df0 = pd.read_csv(r'train.csv')\n",
    "df = df0.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(text):\n",
    "    try:\n",
    "        return float(text[:-8])\n",
    "    except TypeError:\n",
    "        return text\n",
    "\n",
    "df[\"product_page_duration\"] = df[\"product_page_duration\"].apply(to_float)\n",
    "df[\"info_page_duration\"] = df[\"info_page_duration\"].apply(to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers - Check for outliers and remove if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "Click <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def remove_outliers_iqr(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    return df_out\n",
    "\n",
    "def remove_outliers_tails(df_in, col_name, L=0.05, U=0.05):\n",
    "    lower = df_in[col_name].quantile(L)\n",
    "    upper = df_in[col_name].quantile(1-U)\n",
    "    df_out = df_in.loc[(df_in[col_name] > lower) & (df_in[col_name] < upper)]\n",
    "    return df_out\n",
    "\n",
    "def remove_outliers_sd(df_in, col_name, tail=3):\n",
    "    sd = df_in[col_name].std()\n",
    "    mean = df_in[col_name].mean()\n",
    "    fence_low  = mean-tail*sd\n",
    "    fence_high = mean+tail*sd\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    return df_out\n",
    "\n",
    "# for each feature, we should decide which method is the best and what the relevant parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MinMax - Manual calculation\n",
    "df_copy[\"norm_votes\"] = (df_copy[\"votes\"] - df_copy[\"votes\"].min()) / (df_copy[\"votes\"].max() - df_copy[\"votes\"].min())\n",
    "\n",
    "# We initialize our scaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "# We fit our scaler\n",
    "min_max_scaler_scaler.fit(X)\n",
    "\n",
    "\n",
    "# Standardization\n",
    "# We initialize our scaler\n",
    "standard_scaler = StandardScaler()\n",
    "# We fit our scaler\n",
    "standard_scaler.fit(X)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "Click <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "#Deleting Missing Values- dropna\n",
    "def dropna (df_in):\n",
    "    return df_in.dropna()\n",
    "\n",
    "#Imputing Missing Values - fillna by mean (numerical)\n",
    "def fillna_by_mean (df_in, col_name):\n",
    "    col = df_in[col_name] \n",
    "    col_mean = col.mean()\n",
    "    col.fillna(col_mean, inplace=True)\n",
    "    return df_in\n",
    "\n",
    "#Imputing Missing Values - fillna by median (numerical)\n",
    "def fillna_by_median (df_in, col_name):\n",
    "    col = df_in[col_name] \n",
    "    col_median = col.median()\n",
    "    col.fillna(col_median, inplace=True)\n",
    "    return df_in\n",
    "\n",
    "#Imputing Missing Values - fillna by most frequent (categorical)\n",
    "def fillna_by_most_frequent (df_in, col_name):\n",
    "    col = df_in[col_name] \n",
    "    col_freq = col.mode()\n",
    "    col.fillna(col_freq[0], inplace=True) # if we have more then one category? !!! think!\n",
    "    return df_in\n",
    "\n",
    "# for each feature, we should decide which method is the best (mean; median; categorical; zero; Constant; KNN - by neighbors?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month, C, user_type, A, internet_browser \n",
    "\n",
    "def categorical_to_numerical(df_in, col_name):\n",
    "    frames = [df_in]\n",
    "    for i in col_name:\n",
    "        a = pd.get_dummies(df_in[i], prefix = i)\n",
    "        frames.append(a)\n",
    "    df_edited = pd.concat(frames, axis = 1)\n",
    "    df_out = df_edited.drop(columns = col_name)\n",
    "    return df_out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we identify?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA or Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_method(df_in, n):\n",
    "    # initialize PCA\n",
    "    pca = PCA(n_components=n)\n",
    "    # Fit the model with the data\n",
    "    pca.fit(df_in)\n",
    "    # apply the PCA on the data (or on new data)\n",
    "    df_out = pca.transform(df_in)\n",
    "    # Percentage of variance explained by each of the selected components (used for plotting also)\n",
    "    #pca.explained_variance_ratio_\n",
    "    # See the components\n",
    "    #pca.components_\n",
    "    return df_out\n",
    "\n",
    "def feature_selection(df_in, col_name, min_val=None, max_val=None):\n",
    "    if min_val == None:\n",
    "        min_val = df_in[col_name].min()\n",
    "    if max_val == None:\n",
    "        max_val=df_in[col_name].max()\n",
    "    df_out = df_in[(df_in[col_name] >= min_val) & (df_in[col_name] <= max_val)]\n",
    "    return df_out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# MinMax Scaling\n",
    "# We transform our X using the scaler we have just fit.\n",
    "scaled_X = min_max_scaler.transform(X)\n",
    "\n",
    "# Standardization\n",
    "# We transform our X using the scaler we have just fit.\n",
    "scaled_X = standard_scaler.transform(X)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something spicy???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5de938ac8e8976f24d0ccfda11927be12abf3c8349e96d2c30b42e5251c1b314"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
